{"metadata":{"kernelspec":{"name":"python","display_name":"Python (Pyodide)","language":"python"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["#since the folders are loacted in the google drive I have written this code to get the access from the google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uGPOpQfkXNn","executionInfo":{"status":"ok","timestamp":1766148701015,"user_tz":-330,"elapsed":4102,"user":{"displayName":"Deevena","userId":"00727400899479529776"}},"outputId":"686fe6a2-fd09-4054-9184-ac260e9c5313"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#Question 6\n","\n","#since the folders are loacted in the google drive I have written this code to get the access from the google drive\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","#read the file\n","data_plants = pd.read_csv(\"/content/drive/SharedFolder/WIDS_Week1/dataset/farm_metrics.csv\")\n","data_plants.columns = [\"plant_id\",\"height_cm\", \"nutrient_level\", \"yield_grams\"]\n","data_plants.head()\n","\n","#since every column is object, we need to convert them to numberic and do the calculations.\n","data_plants[\"height_cm\"] = pd.to_numeric(data_plants[\"height_cm\"])\n","data_plants[\"nutrient_level\"] = pd.to_numeric(data_plants[\"nutrient_level\"])\n","data_plants[\"yield_grams\"] = pd.to_numeric(data_plants[\"yield_grams\"])\n","\n","#task:mean , median, var of plant height\n","hght = data_plants[\"height_cm\"].to_numpy()\n","mean_of_plants_height = np.mean(hght);\n","median_of_plants_height = np.median(hght);\n","variance_of_plants_height = np.var(hght);\n","print(\"mean of the plans height:\", mean_of_plants_height)\n","print(\"median of the plans height:\", median_of_plants_height)\n","print(\"variance of the plans height:\", variance_of_plants_height)\n","\n","#task: correlation btw nutrient and yield\n","nut = data_plants[\"nutrient_level\"].to_numpy();\n","yeld = data_plants[\"yield_grams\"].to_numpy();\n","cormat = np.corrcoef(nut, yeld);\n","cny = cormat[0,1];\n","print(\"Correlation nutrient vs yield:\",cny)\n","\n","#generate simulated yield vals from a normal distribution\n","sim_yields = np.random.normal(loc=np.mean(yeld), scale=np.std(yeld),size=1000)\n","\n","#matrix transpose + inver of the nutrient interaction matrix (matrix columns are the height,nutrients, yield values)\n","nutrient_matrix = data_plants[[\"height_cm\", \"nutrient_level\", \"yield_grams\"]].to_numpy()\n","transpose_matrix = nutrient_matrix.T\n","#since the matrix is not square matrix and we need to do inverse, we use linalg pseudo-inverse which works for non square matrix or for non invertable matrices\n","inverse = np.linalg.pinv(nutrient_matrix)\n","sum_matrix = transpose_matrix + inverse\n","print(\"transpose + inverse of the nutrient matrix:\\n\", sum_matrix)\n","\n","#scatter plot of nutrient_level vs yield\n","plt.figure()\n","plt.scatter(nut, yeld)\n","plt.xlabel(\"Nutrient level\")\n","plt.ylabel(\"Yield in grams\")\n","plt.title(\"Scatter plot of Nutrient level vs Yield\")\n","plt.show()\n","\n","#histogram of simulated yields (sim_yields)\n","plt.figure(figsize=(10,7))\n","plt.hist(sim_yields, bins=50, color='green', alpha=0.6)\n","plt.xlabel(\"Yield in grams\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Histogram of Simulated Yields\")\n","plt.grid(True, alpha=0.3)\n","plt.show()\n"],"metadata":{"id":"YspPRXr-l64w","colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"beff0f19-a578-4b8e-8624-80d59787c736","trusted":true,"executionInfo":{"status":"error","timestamp":1766148745345,"user_tz":-330,"elapsed":42,"user":{"displayName":"Deevena","userId":"00727400899479529776"}},"collapsed":true},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/SharedFolder/WIDS_Week1/dataset/farm_metrics.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4008805620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#read the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata_plants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/SharedFolder/WIDS_Week1/dataset/farm_metrics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata_plants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"plant_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"height_cm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nutrient_level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yield_grams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_plants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/SharedFolder/WIDS_Week1/dataset/farm_metrics.csv'"]}],"execution_count":14},{"cell_type":"code","source":["#Question 7\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#read the file\n","coords = pd.read_csv(\"/content/drive/MyDrive/WIDS_Week1/dataset/sonar_points.csv\")\n","coords.columns = [\"x\", \"y\", \"z\"]\n","#extract the coordinates\n","x_axis = coords[\"x\"]\n","y_axis = coords[\"y\"]\n","z_axis = coords[\"z\"]\n","\n","#distance of all points from origin (0,0,0)\n","all_distances = np.sqrt(x_axis**2 + y_axis**2 + z_axis**2)\n","print(all_distances)\n","\n","#normalization of the coordinates with given info - mean = 0, var =1, formula to normal is -> normalised = ((given std i.e root of var)(x_axis - mean of the x_axis points)/std of x_axis) + given mean\n","x_norm = (x_axis - np.mean(x_axis)) / np.std(x_axis)\n","y_norm = (y_axis - np.mean(y_axis)) / np.std(y_axis)\n","z_norm = (z_axis - np.mean(z_axis)) / np.std(z_axis)\n","\n","new_coords = np.column_stack((x_norm, y_norm, z_norm))\n","print(new_coords)\n","\n","'''\n","covariance matrix of the points,\n"," rowvar=False is used because each column represents a variable (x, y, z) and each row represents an observation,\n"," normalised coords have been used because the results have to be fair between each value, for ex: x = 2, y = 4, z =200 here z will dominate only because its value is higher, after we normalise each of the points all have comparable spread and all points will contribute equally and shows true relationship between each other points\n","'''\n","cov_mat = np.cov(new_coords, rowvar=False)\n","print(cov_mat)\n","\n","#2D scallter plot x vs y\n","plt.figure()\n","plt.scatter(x_axis, y_axis)\n","plt.xlabel(\"X coordinate\")\n","plt.ylabel(\"Y coordinate\")\n","plt.title(\"2D Scatter plot of sonar points (x vs y)\")\n","plt.show()\n","\n","#histogram of depth (z)\n","plt.figure(figsize=(10,7))\n","plt.hist(z_axis, bins=50, color='green', alpha=0.6)\n","plt.xlabel(\"Depth(Z coordinate)\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Histogram of Depth Values(Z)\")\n","plt.grid(True, alpha=0.3)\n","plt.show()\n","\n","\n"],"metadata":{"id":"3ceBbhxqycLc","trusted":true,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["#Question 8\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","#read the file\n","choco = pd.read_csv(\"/content/drive/MyDrive/WIDS_Week1/dataset/choco_quality.csv\")\n","\n","#1.remove missing values using pandas\n","new_choco = choco.dropna()\n","# print(\"Original shape:\", choco.shape)\n","# print(\"After removing missing values:\", new_choco.shape)\n","\n","#2.use inbuilt decribe function to describe statistics\n","new_choco.describe()\n","\n","#3.computation of quality score = 0.3sugar + 0.7cocoa\n","#extract sugar and cocoa\n","sugar = new_choco[\"sugar\"].to_numpy()\n","cocoa = new_choco[\"cocoa\"].to_numpy()\n","\n","quality_score = 0.3 * sugar + 0.7 * cocoa\n","print(\"Quality Score:\", quality_score)\n","\n","#4.generate randome noise\n","noise = np.random.normal(loc=0, scale=1, size=len(quality_score))\n","\n","#5.scatter plot cocoa % vs sugar %\n","plt.figure()\n","plt.scatter(cocoa, sugar)\n","plt.xlabel(\"Cocoa Percentage\")\n","plt.ylabel(\"Sugar Percentage\")\n","plt.title(\"Cocoa % vs Sugar %\")\n","plt.show()\n","\n","#6.histogram of weight distribution\n","# Extract weight values\n","w = new_choco[\"weight\"].to_numpy()\n","\n","plt.figure()\n","plt.hist(w, bins=30, color='green', alpha=0.6)\n","plt.xlabel(\"Weight\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Distribution of Chocolate Bar Weights\")\n","plt.grid(True, alpha=0.3)\n","plt.show()\n","\n","\n"],"metadata":{"id":"mgU71f2ryciR","trusted":true},"outputs":[],"execution_count":null}]}